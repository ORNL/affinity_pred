#!/usr/bin/env bash
#BSUB -P BIP214
#BSUB -W 4:00
#BSUB -q batch
#BSUB -nnodes 128
#BSUB -J finetune
#BSUB -o finetune.o%J
#BSUB -e finetune.e%J
##BSUB -w ended(1042856)

source activate /gpfs/alpine/world-shared/bip214/opence-env

export HF_HOME=/gpfs/alpine/world-shared/bip214/affinity_pred/train
export TORCH_EXTENSIONS_DIR=/gpfs/alpine/world-shared/bip214/affinity_pred/train/build

module load cuda/10.2

# undo some conda env variables
export CC=`which gcc`
export GCC=`which gcc`
export CXX=`which g++`

# open files limit (for more than ~1000 nodes)
ulimit -n 14000
export OMP_NUM_THREADS=1

BAD_HOSTS=`jsrun -r 1 -g6 -a 1 -c 42 --smpiargs="-disable_gpu_hooks" ./check_gpu.sh`
BAD_HOSTS=`echo ${BAD_HOSTS} | paste -sd "," -`

if [[ $BAD_HOSTS = *[!\ ]* ]]; then
    echo "Bad GPUs on: $BAD_HOSTS"
    BAD_HOSTS="-x ${BAD_HOSTS}"
fi

# clear stale lock files
rm -f `find -name *lock`

jsrun $BAD_HOSTS -r 1 -g6 -a 6 -c 42 python ../affinity_pred/finetune.py \
    --deepspeed='ds_config_scale.json'\
    --output_dir='./results_n128'\
    --num_train_epochs=15\
    --per_device_train_batch_size=16\
    --per_device_eval_batch_size=16\
    --warmup_steps=5\
    --learning_rate=3e-05\
    --weight_decay=3e-7\
    --logging_dir='./logs'\
    --logging_steps=1\
    --evaluation_strategy="epoch"\
    --gradient_accumulation_steps=1\
    --fp16=True\
    --run_name="seq_smiles_affinity"\
    --save_strategy="epoch"\
    --seed=42
