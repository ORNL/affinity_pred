{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e485a80c-9860-4353-ab15-f089e70db5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bcb6ba-ca10-41bc-88e9-72c3c88ac754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41cdb3c9-6e57-4115-a13a-e28c90e748ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 13:56:26.110932: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, Trainer\n",
    "from transformers import EvalPrediction\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve \n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047c0e9a-fcf0-4576-8c72-4477a1a30026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the transformer model\n",
    "from affinity_pred.model import EnsembleSequenceRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387b534-72e4-4555-9907-fcc21bb33a95",
   "metadata": {},
   "source": [
    "**Load tokenizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e0e52c-d562-49e4-ba81-8af6197218df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "61fed0e3909b4ffdb9fa63af2d11ed57",
      "92c751b2131d4e2c80b74fbc14bdb336",
      "a0c69121214141f69a0a87a58cb51c30",
      "8e1b6f7b25d649fbaa438532cfdb752f",
      "77a5293bd3534f20b501dfc96a51cc99",
      "e32bc21b1eaf4d5d9d3f3a6640e4abca",
      "120a440f97314b6e8a57ab8ea6e5d5d5",
      "ef4dafc982a54db8848b9de1c7908d83",
      "5d556484fe1e4083acf908dd0d12f7e1",
      "c5de19ef8a4448309f273e0b8521421f",
      "73d3903838c240609e96efa22ee186d2",
      "0bb842e9a84140d2b133faec60f95751",
      "f8634649ebe04f298c714553c6e2e458",
      "7e2f74ec25d14322a0134da26f06ae17",
      "00928a43a2144a9db6887c55840c935d",
      "a17febc83a664350b8b16a93393a1995",
      "59bdec7a3edc4889908028ab96a299e6",
      "d18e735bcaf94b8faba345390f536dde",
      "81f57dc31be14707a209da3a977b63d2",
      "db6d3ad67a6148b08c4b027929084edf",
      "d50bd7359ad243c88258215712b5625b",
      "1700319ee4684cc19a3161fcb31f0552",
      "5fb6b0ef420c4ff7bc50c40ca9a073c8",
      "b9d9d0dd9d49415e814fbe22f1167c1c",
      "a6bc0f9b315644bb9f0923d769ae96b0",
      "00d0ed6f1533493cabad4ea515c7ed33",
      "328cfec0b3a74866a9aedcd0508d8814",
      "812e2d4457df4429a790608ca7692775",
      "afb7ba247e8f4bc78784ab37a1fd4a8f",
      "4df075ac94c343dca6d10c52eaca496b",
      "564ad9e660ab409aaf45c4daff685ecd",
      "2de1a796d6e243b98cda57130ff755f3",
      "9b943243af3a4dd5a32aec401b7b5e65",
      "e95d92f6adfb4649b4951f44dec59432",
      "b9cfa3e6d02d42488c19fad601f85bb0",
      "904198129e3e4c41af2e3bac94cee8f9",
      "1dde216bf5a14276a48741e39e139e12",
      "b581f3171a1848539532041eb13997c7",
      "54d479edb35949ca908d3eb723986ff9",
      "818b07669db94bdcbf14fab6a5493a3d"
     ]
    },
    "id": "k4gHJNTKSi_b",
    "outputId": "4fe26c11-c45a-49d2-eb16-9b9c375d6070"
   },
   "outputs": [],
   "source": [
    "seq_model_name = \"Rostlab/prot_bert_bfd\"\n",
    "seq_tokenizer = AutoTokenizer.from_pretrained(seq_model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db5a219-6bca-4e43-a18f-0225a50a90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_model_name = 'mossaic-candle/bert-gb-2021'\n",
    "smiles_tokenizer =  AutoTokenizer.from_pretrained(smiles_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ffc0ee-7958-4ecd-a259-5f873ea2c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_seqs(seqs):\n",
    "    input_fixed = [\"\".join(seq.split()) for seq in seqs]\n",
    "    input_fixed = [re.sub(r\"[UZOB]\", \"X\", seq) for seq in input_fixed]\n",
    "    return [list(seq) for seq in input_fixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d058edd-11f5-49c7-a5b6-b82d69c3857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on-the-fly tokenization\n",
    "\n",
    "# the maximum length of a protein seqeuence (for inference)\n",
    "max_seq_length=512\n",
    "\n",
    "# the maximum length of a SMILES sequence\n",
    "max_smiles_length=256\n",
    "\n",
    "def encode(item):\n",
    "        seq_encodings = seq_tokenizer(expand_seqs(item['seq'])[0],\n",
    "                                      truncation=True,\n",
    "                                      padding='max_length',\n",
    "                                      max_length=max_seq_length,\n",
    "                                      is_split_into_words=True)\n",
    "        \n",
    "        # use RDkit canonical SMILES        \n",
    "        if 'smiles_can' in item:\n",
    "            smiles = item['smiles_can'][0]\n",
    "        else:\n",
    "            smiles = item['smiles'][0]\n",
    "            \n",
    "        smiles_encodings = smiles_tokenizer(smiles,\n",
    "                                            padding='max_length',\n",
    "                                            truncation=True,\n",
    "                                            max_length=max_smiles_length)\n",
    "        \n",
    "        # concatenate the two different inputs\n",
    "        item['input_ids'] = [torch.cat([torch.tensor(seq_encodings['input_ids']),\n",
    "                                        torch.tensor(smiles_encodings['input_ids'])])]\n",
    "        item['attention_mask'] = [torch.cat([torch.tensor(seq_encodings['attention_mask']),\n",
    "                                        torch.tensor(smiles_encodings['attention_mask'])])]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18092754-9f18-43b9-9ab3-616b784160b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffinityDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        #affinity = item['neg_log10_affinity_M']\n",
    "        affinity = item['affinity']\n",
    "        item['labels'] = float(affinity)\n",
    "        \n",
    "        # drop the non-encoded input\n",
    "        item.pop('smiles')\n",
    "        item.pop('smiles_can')\n",
    "        item.pop('seq')\n",
    "        item.pop('neg_log10_affinity_M')\n",
    "        item.pop('affinity_uM')\n",
    "        item.pop('affinity')\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2b9ad-809e-4a82-bea6-0b26ca143b4b",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48ad68de-add2-4736-8579-b1087816ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    model = EnsembleSequenceRegressor(seq_model_name, smiles_model_name, max_seq_length=max_seq_length)\n",
    "\n",
    "    # select one of the following ensemble members\n",
    "    #model_name = 'bert_1'\n",
    "    #model_name = 'bert_2'\n",
    "    #model_name = 'bert_3'\n",
    "    model_name = 'bert_4'\n",
    "    #model_name = 'bert_5'\n",
    "\n",
    "    # download the weights\n",
    "    fn = hf_hub_download(repo_id=\"jglaser/affinity_pred_{}\".format(model_name), filename='pytorch_model.bin')\n",
    "    checkpoint = torch.load(fn)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5488ef7d-6c17-4543-897e-ada3be382b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds_list, out_label_list = p.predictions, p.label_ids\n",
    "\n",
    "    return {\n",
    "        \"mse\": mean_squared_error(out_label_list, preds_list),\n",
    "        \"mae\": mean_absolute_error(out_label_list, preds_list),\n",
    "        \"spearman_rho\": spearmanr(out_label_list, preds_list).correlation,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6cd68220-b6ed-487e-ae99-c52cc6b0896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at /ccs/home/glaser/.cache/huggingface/hub/models--Rostlab--prot_bert_bfd/snapshots/6c5c8a55a52ff08a664dfd584aa1773f125a0487/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 40000,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 30,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /ccs/home/glaser/.cache/huggingface/hub/models--Rostlab--prot_bert_bfd/snapshots/6c5c8a55a52ff08a664dfd584aa1773f125a0487/pytorch_model.bin\n",
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at Rostlab/prot_bert_bfd.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading configuration file config.json from cache at /ccs/home/glaser/.cache/huggingface/hub/models--mossaic-candle--bert-gb-2021/snapshots/5be989bd490050560651deb58427d2cdce5ef955/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /ccs/home/glaser/.cache/huggingface/hub/models--mossaic-candle--bert-gb-2021/snapshots/5be989bd490050560651deb58427d2cdce5ef955/pytorch_model.bin\n",
      "Some weights of the model checkpoint at mossaic-candle/bert-gb-2021 were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at mossaic-candle/bert-gb-2021 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d641851db0be4ec68b7955b51a4172d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:1226\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1224\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, temp_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstoring \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, blob_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:493\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001b[0m\n\u001b[1;32m    492\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n\u001b[0;32m--> 493\u001b[0m         \u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m progress\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/tempfile.py:473\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;129m@_functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# the instantiated Transformers model to be trained\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# evaluation metric\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# reduce if running out of memory\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                           \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:333\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init \u001b[38;5;241m=\u001b[39m model_init\n\u001b[0;32m--> 333\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer` requires either a `model` or `model_init` argument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:1238\u001b[0m, in \u001b[0;36mTrainer.call_model_init\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m   1236\u001b[0m model_init_argcount \u001b[38;5;241m=\u001b[39m number_of_arguments(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init)\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_init_argcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1238\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_init_argcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1240\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init(trial)\n",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36mmodel_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#model_name = 'bert_5'\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# download the weights\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjglaser/affinity_pred_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpytorch_model.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(fn)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:1226\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_file_manager() \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n\u001b[1;32m   1224\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, temp_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m-> 1226\u001b[0m     http_get(\n\u001b[1;32m   1227\u001b[0m         url_to_download,\n\u001b[1;32m   1228\u001b[0m         temp_file,\n\u001b[1;32m   1229\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1230\u001b[0m         resume_size\u001b[38;5;241m=\u001b[39mresume_size,\n\u001b[1;32m   1231\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1232\u001b[0m     )\n\u001b[1;32m   1234\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstoring \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in cache at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, blob_path)\n\u001b[1;32m   1235\u001b[0m os\u001b[38;5;241m.\u001b[39mreplace(temp_file\u001b[38;5;241m.\u001b[39mname, blob_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/tempfile.py:491\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__exit__\u001b[0;34m(self, exc, value, tb)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc, value, tb):\n\u001b[0;32m--> 491\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,                # the instantiated Transformers model to be trained\n",
    "    compute_metrics = compute_metrics,    # evaluation metric\n",
    "    args=TrainingArguments(per_device_eval_batch_size=32, # reduce if running out of memory\n",
    "                           output_dir='results'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1307f-e5e6-41ad-b4ab-c33eb8a4a159",
   "metadata": {},
   "source": [
    "**Test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe592c4e-9829-4dbe-b830-c2459566c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = load_dataset(\"jglaser/binding_affinity\",split='train')\n",
    "split = data_all.train_test_split(train_size=1000)\n",
    "test = split['train']\n",
    "test.set_transform(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6e04e-ca46-4144-a3f4-bec4abd16302",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AffinityDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6ab56-45af-433f-90f2-2e9cb2859f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca03e10-3ca8-4cab-83e0-8ee28debaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-normalize predictions [to -log_10 affinity[M] units]\n",
    "field_log10 = 'neg_log10_affinity_M'\n",
    "mean, var = (np.mean(data_all[field_log10]), np.var(data_all[field_log10]))\n",
    "def scale(x):\n",
    "    return x*np.sqrt(var)+mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b0f4d-82f8-4df6-a2ec-ce60636aa713",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.metrics['test_mse'] * var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d9060-624c-4a63-92ab-d9a1096b39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.metrics['test_spearman_rho']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb19ce-8d41-4535-9132-caaddd89ebd4",
   "metadata": {},
   "source": [
    "**PostEra Mpro dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77669b-8394-41e4-89ac-a61bf95ca248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARS-CoV main protease\n",
    "mpro_seq_5r84 = \"SGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGHSMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGVYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCYMHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYEPLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db16f42-3246-4608-b3ad-e2f7fe11e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mpro_seq_5r84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c576d7c-9aa1-46a9-b9ed-6ccd76353e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosteraDataset(Dataset):\n",
    "    def __init__(self, df, mean, var, seq):\n",
    "        self.df = df\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "        self.seq = seq\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        item = {'smiles': [row.SMILES], 'seq': [self.seq]}\n",
    "        item = encode(item)\n",
    "        \n",
    "        # get first (single) item\n",
    "        item['input_ids'] = item['input_ids'][0]\n",
    "        item['attention_mask'] = item['attention_mask'][0]\n",
    "        \n",
    "        affinity = 6-np.log(row['f_avg_IC50'])/np.log(10)\n",
    "        affinity = (affinity-self.mean)/np.sqrt(self.var)\n",
    "        item['labels'] = float(affinity)\n",
    "        \n",
    "        # drop the non-encoded input\n",
    "        item.pop('smiles')\n",
    "        item.pop('seq')\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6eda5f-1b30-48d2-9777-b4208e21d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/activity_data.csv')\n",
    "df = df[~df['f_avg_IC50'].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cc1cd-511d-4f7f-9473-14fc05fcfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "postera_dataset = PosteraDataset(df=df, mean=mean, var=var, seq=mpro_seq_5r84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442efaf3-39ef-451b-a52b-4884d570ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(postera_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723c658-6a38-45f5-9369-3a56563977fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=trainer.predict(postera_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bb19f-1c7d-4897-a378-1d1927cb0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.metrics['test_mse'] * var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d3dcd-8887-4054-b4b1-170112c8b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.metrics['test_spearman_rho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cc723-d2de-44ce-830f-f5340cc23f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = scale(y.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391a135-e288-4753-98a3-0a863a344873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thresh = 2.5 # the activity threshold in uM below which a ground truth sample is considered 'active'\n",
    "nbootstrap = 500\n",
    "samplesize = 100\n",
    "x = np.linspace(0,1,100)\n",
    "\n",
    "ps = []\n",
    "for i in range(nbootstrap):\n",
    "    df_sample = df.sample(n=samplesize,replace=True)\n",
    "    yr = df_sample.f_avg_IC50 < thresh\n",
    "    #yr = df_sample.f_inhibition_at_20_uM > thresh\n",
    "    p, r, _ = precision_recall_curve(yr, df_sample.prediction)\n",
    "    ps.append(np.interp(x,r[::-1],p[::-1]))\n",
    "    \n",
    "ps = np.vstack(ps)\n",
    "pavg = np.mean(ps,axis=0)\n",
    "perr = np.std(ps,axis=0)\n",
    "auc = np.trapz(pavg[::-1],x)\n",
    "alpha_err = 0.15\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(9,6)\n",
    "\n",
    "ax.plot(x, pavg, label='AUC={:.5f}, thresh={} $\\\\mathrm{{\\\\mu M}}$'.format(auc,thresh),color='r',lw=4)\n",
    "ax.fill_between(x, pavg - perr, pavg + perr, color='r', alpha=alpha_err)\n",
    "\n",
    "ax.axhline(pavg[-1], dashes=[5.0,5.0], color='k')\n",
    "\n",
    "ax.set_ylim(0,1)\n",
    "\n",
    "ax.set_xlabel('recall',fontsize=36)\n",
    "ax.set_ylabel('precision',fontsize=36)\n",
    "ax.set_ylim(0,1)\n",
    "ax.tick_params(labelsize=22)\n",
    "l = ax.legend(frameon=False,title='PostEra Mpro dataset',fontsize=22)\n",
    "l.get_title().set_fontsize(22)\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig('postera_pr_{:.2f}.png'.format(thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc19b35-1518-41a5-b16e-dd588c29ed46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCF-CUDA11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
